{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single-voxel simulations\n",
    "\n",
    "Monte-Carlo simulations were performed for a single-voxel representative of white-matter, to evaluate the impact of each subsampling method (OptSC vs OptTRUNC) on the estimation of diffusion parameters derived from DTI (i.e., FA, MD, AD, and RD maps) and DKI (i.e., MK, AK, and RK maps). We simulated the diffusion-weighted signal under different background noise conditions (SNR=10, 20, 30, 40, 50, 1000).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: dipy in /home/afouto/.local/lib/python3.8/site-packages (1.1.1)\n",
      "Requirement already satisfied: h5py>=2.4.0 in /home/afouto/.local/lib/python3.8/site-packages (from dipy) (2.10.0)\n",
      "Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.8/dist-packages (from dipy) (1.8.0)\n",
      "Requirement already satisfied: nibabel>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from dipy) (3.2.2)\n",
      "Requirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.8/dist-packages (from h5py>=2.4.0->dipy) (1.22.3)\n",
      "Requirement already satisfied: six in /home/afouto/PROJECTS/virtualenvs/project-dwi_subsampling/lib/python3.8/site-packages (from h5py>=2.4.0->dipy) (1.15.0)\n",
      "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.8/dist-packages (from nibabel>=3.0.0->dipy) (21.3)\n",
      "Requirement already satisfied: setuptools in /home/afouto/PROJECTS/virtualenvs/project-dwi_subsampling/lib/python3.8/site-packages (from nibabel>=3.0.0->dipy) (44.0.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/afouto/PROJECTS/virtualenvs/project-dwi_subsampling/lib/python3.8/site-packages (from packaging>=14.3->nibabel>=3.0.0->dipy) (2.4.7)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install dipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import multiprocessing\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "# DTI and DKI module\n",
    "import dipy.reconst.dki as dki\n",
    "import dipy.reconst.dti as dti\n",
    "#import matplotlib.gridspec as gridspec\n",
    "\n",
    "# module to load nifti images\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "\n",
    "# fucntion to construct gradient table and design matrix\n",
    "from dipy.core.gradients import gradient_table\n",
    "from dipy.core.sphere import HemiSphere, disperse_charges\n",
    "#from dipy.data import fetch_stanford_hardi, read_stanford_hardi\n",
    "from dipy.io.gradients import read_bvals_bvecs\n",
    "from dipy.data import (get_fnames, get_sphere)\n",
    "\n",
    "# function to compute quadratic form of tensor from evals and evecs\n",
    "from dipy.reconst.vec_val_sum import vec_val_vect\n",
    "from dipy.reconst.dki import decompose_tensor, Wrotate\n",
    "from dipy.viz import window, actor\n",
    "\n",
    "# fucntion to add noise to simulated data\n",
    "from dipy.sims.voxel import dki_signal, multi_tensor_dki, _check_directions, all_tensor_evecs, kurtosis_element\n",
    "\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dki_signal(info):\n",
    "    np.random.seed(None)\n",
    "    noisy = dki_signal(\n",
    "        info[1],\n",
    "        info[2], \n",
    "        info[3], \n",
    "        S0=info[4],\n",
    "        snr=info[5],\n",
    "    )\n",
    "    return [info[0], noisy]\n",
    "\n",
    "\n",
    "def multi_tensor_dki_edited(gtab, mevals, S0, angles, fractions, snr):\n",
    "    if np.round(np.sum(fractions), 2) != 100.0:\n",
    "        raise ValueError('Fractions should sum to 100')\n",
    "\n",
    "    fractions = [f / 100. for f in fractions]\n",
    "    sticks = _check_directions(angles)\n",
    "\n",
    "    # computing a 3D matrix containing the individual DT components\n",
    "    D_comps = np.zeros((len(fractions), 3, 3))\n",
    "    for i in range(len(fractions)):\n",
    "        R = all_tensor_evecs(sticks[i])\n",
    "        D_comps[i] = np.dot(np.dot(R, np.diag(mevals[i])), R.T)\n",
    "\n",
    "    # compute voxel's DT\n",
    "    DT = np.zeros((3, 3))\n",
    "    for i in range(len(fractions)):\n",
    "        DT = DT + fractions[i]*D_comps[i]\n",
    "    dt = np.array([DT[0][0], DT[0][1], DT[1][1], DT[0][2], DT[1][2], DT[2][2]])\n",
    "\n",
    "    # compute voxel's MD\n",
    "    MD = (DT[0][0] + DT[1][1] + DT[2][2]) / 3\n",
    "\n",
    "    # compute voxel's KT\n",
    "    kt = np.zeros(15)\n",
    "    kt[0] = kurtosis_element(D_comps, fractions, 0, 0, 0, 0, DT, MD)\n",
    "    kt[1] = kurtosis_element(D_comps, fractions, 1, 1, 1, 1, DT, MD)\n",
    "    kt[2] = kurtosis_element(D_comps, fractions, 2, 2, 2, 2, DT, MD)\n",
    "    kt[3] = kurtosis_element(D_comps, fractions, 0, 0, 0, 1, DT, MD)\n",
    "    kt[4] = kurtosis_element(D_comps, fractions, 0, 0, 0, 2, DT, MD)\n",
    "    kt[5] = kurtosis_element(D_comps, fractions, 0, 1, 1, 1, DT, MD)\n",
    "    kt[6] = kurtosis_element(D_comps, fractions, 1, 1, 1, 2, DT, MD)\n",
    "    kt[7] = kurtosis_element(D_comps, fractions, 0, 2, 2, 2, DT, MD)\n",
    "    kt[8] = kurtosis_element(D_comps, fractions, 1, 2, 2, 2, DT, MD)\n",
    "    kt[9] = kurtosis_element(D_comps, fractions, 0, 0, 1, 1, DT, MD)\n",
    "    kt[10] = kurtosis_element(D_comps, fractions, 0, 0, 2, 2, DT, MD)\n",
    "    kt[11] = kurtosis_element(D_comps, fractions, 1, 1, 2, 2, DT, MD)\n",
    "    kt[12] = kurtosis_element(D_comps, fractions, 0, 0, 1, 2, DT, MD)\n",
    "    kt[13] = kurtosis_element(D_comps, fractions, 0, 1, 1, 2, DT, MD)\n",
    "    kt[14] = kurtosis_element(D_comps, fractions, 0, 1, 2, 2, DT, MD)\n",
    "\n",
    "    # compute S based on the DT and KT\n",
    "    S = dki_signal(gtab, dt, kt, S0, snr)\n",
    "\n",
    "    return S, dt, kt, DT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# Defining working directories:\n",
    "# ------------------------------------------------------------------------------\n",
    "cwd = Path.cwd()\n",
    "path_sims = cwd\n",
    "path_sc = path_sims / \"03-anisotropic_voxel/sc\"\n",
    "path_trunc = path_sims / \"03-anisotropic_voxel/trunc\"\n",
    "path_random = path_sims / \"03-anisotropic_voxel/random\"\n",
    "path_to_save = path_sims / \"05-sims_signal-nifti_multi_tensor/independent\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# Defining simulation parameters\n",
    "# ------------------------------------------------------------------------------\n",
    "# The experiment is repeated for 100 diffusion tensor directions and 100 noise repeats\n",
    "nReps = 100  # number of noise instances\n",
    "nDTdirs = 100  # number of tensor directions\n",
    "SNR = [10, 20, 30, 40, 50, 1000]  # noise levels\n",
    "subsets = [\"full\", \"subset5\", \"subset10\", \"subset20\", \"subset30\", \"subset40\", \"subset50\"] \n",
    "methods = [\"sc\", \"trunc\", \"random\"] # two different subsampling methods\n",
    "\n",
    "# number of activated cores for parallel processing:\n",
    "n_cores = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S0 signal for a voxel with only tissue is 230.11526488059488\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# Ground truth parameters:\n",
    "# ------------------------------------------------------------------------------\n",
    "# Reference for GT parameters: doi:10.3389/fnhum.2021.675433\n",
    "# ------------------------------------------------------------------------------\n",
    "# 1. Simulating diffusion tensor & kurtosis tensor\n",
    "# ------------------------------------------------------------------------------\n",
    "eval1 = [1.4e-3, 0.1e-3, 0.1e-3]\n",
    "eval2 = [2e-3, 0.5e-3, 0.5e-3]\n",
    "eval3 = [1.4e-3, 0.1e-3, 0.1e-3]\n",
    "eval4 = [2e-3, 0.5e-3, 0.5e-3]\n",
    "angle1 = (30.0, 0.0)\n",
    "angle2 = (30.0, 0.0)\n",
    "angle3 = (150.0, 0.0)\n",
    "angle4 = (150.0, 0.0)\n",
    "stick1 = _check_directions([angle1])\n",
    "stick2 = _check_directions([angle2])\n",
    "stick3 = _check_directions([angle3])\n",
    "stick4 = _check_directions([angle4])\n",
    "evec1 = all_tensor_evecs(stick1[0])\n",
    "evec2 = all_tensor_evecs(stick2[0])\n",
    "evec3 = all_tensor_evecs(stick3[0])\n",
    "evec4 = all_tensor_evecs(stick4[0])\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 3. Simulating S0 signal\n",
    "# ------------------------------------------------------------------------------\n",
    "# Parameters that define the unweighted signal at 3T (assuming no T1 relaxation):\n",
    "\n",
    "# T2 relaxation (ms)\n",
    "T2_tissue = 80  # Wansapura et al., 1999\n",
    "\n",
    "# Proton density (percentage units)\n",
    "PD_tissue = 70  # Abbas et al., 2015\n",
    "\n",
    "# TE (ms) \n",
    "TE = 89 # MIG_N2Treat project protocol\n",
    "\n",
    "# Assuming no T1 relaxation, the non-weighted signal for a voxel that has only tisssue or only water:\n",
    "k = 10\n",
    "S0_sims = k * PD_tissue * np.exp(-TE / T2_tissue)\n",
    "\n",
    "print('S0 signal for a voxel with only tissue is ' + str(S0_sims))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# Simulate tensor rotations:\n",
    "# ------------------------------------------------------------------------------\n",
    "theta = np.pi * np.random.rand(nDTdirs)\n",
    "phi = 2 * np.pi * np.random.rand(nDTdirs)\n",
    "hsph_initial = HemiSphere(theta=theta, phi=phi)\n",
    "hsph_updated, potential = disperse_charges(hsph_initial, 5000)\n",
    "DTdirs = hsph_updated.vertices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# Ground truth parameters:\n",
    "# ------------------------------------------------------------------------------\n",
    "mevals = [eval1, eval2, eval3, eval4]\n",
    "angles = [angle1, angle2, angle3, angle4]\n",
    "fractions = [25.0, 25.0, 25.0, 25.0]\n",
    "\n",
    "bv1 = \"full_sc_b0b1000b2000.bvec\"\n",
    "bv2 = \"full_sc_b0b1000b2000.bval\"\n",
    "\n",
    "fbvecs = os.path.join(path_sc, bv1)\n",
    "fbvals = os.path.join(path_sc, bv2)\n",
    "\n",
    "bvals, bvecs = read_bvals_bvecs(str(fbvals), str(fbvecs))\n",
    "gtab = gradient_table(bvals, bvecs, b0_threshold=0)\n",
    "\n",
    "signal4_gt, dt0, kt0, DT0 = multi_tensor_dki_edited(gtab, mevals, S0_sims, angles, fractions, snr=None)\n",
    "\n",
    "dki_model = dki.DiffusionKurtosisModel(gtab, fit_method='NLS')\n",
    "dki_fit = dki_model.fit(signal4_gt)\n",
    "md_gt = dki_fit.md\n",
    "ad_gt = dki_fit.ad\n",
    "rd_gt = dki_fit.rd\n",
    "fa_gt = dki_fit.fa\n",
    "\n",
    "mk_gt = dki_fit.mk()\n",
    "ak_gt = dki_fit.ak()\n",
    "rk_gt = dki_fit.rk()\n",
    "\n",
    "print(fa_gt, md_gt, ad_gt, rd_gt)\n",
    "print(mk_gt, ak_gt, rk_gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating single-voxel DWIs...\n",
      "Processing sc---------------------------------\n",
      "Processing snr:10---------------------------------\n",
      "Processing full---------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 35/100 [00:24<00:45,  1.42it/s]Process ForkPoolWorker-432:\n",
      "Process ForkPoolWorker-430:\n",
      "Process ForkPoolWorker-422:\n",
      "Process ForkPoolWorker-425:\n",
      "Process ForkPoolWorker-427:\n",
      "Process ForkPoolWorker-421:\n",
      "Process ForkPoolWorker-424:\n",
      "Process ForkPoolWorker-426:\n",
      "Process ForkPoolWorker-431:\n",
      "Process ForkPoolWorker-429:\n",
      "Process ForkPoolWorker-428:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Process ForkPoolWorker-423:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 356, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/connection.py\", line 414, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/afouto/PROJECTS/MIGRAINE/4_Conferences/2020_ESMRMB/11-Simulations/v011-simulate_xx_snr_independent_corrected.ipynb Cell 11\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/afouto/PROJECTS/MIGRAINE/4_Conferences/2020_ESMRMB/11-Simulations/v011-simulate_xx_snr_independent_corrected.ipynb#X13sZmlsZQ%3D%3D?line=59'>60</a>\u001b[0m \u001b[39m# Busy-waiting: until work is done, check whether any worker dies (in that case, PIDs would change!)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/afouto/PROJECTS/MIGRAINE/4_Conferences/2020_ESMRMB/11-Simulations/v011-simulate_xx_snr_independent_corrected.ipynb#X13sZmlsZQ%3D%3D?line=60'>61</a>\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mnot\u001b[39;00m fitresults\u001b[39m.\u001b[39mready():\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/afouto/PROJECTS/MIGRAINE/4_Conferences/2020_ESMRMB/11-Simulations/v011-simulate_xx_snr_independent_corrected.ipynb#X13sZmlsZQ%3D%3D?line=61'>62</a>\u001b[0m     fitpool_pids_new \u001b[39m=\u001b[39m [\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/afouto/PROJECTS/MIGRAINE/4_Conferences/2020_ESMRMB/11-Simulations/v011-simulate_xx_snr_independent_corrected.ipynb#X13sZmlsZQ%3D%3D?line=62'>63</a>\u001b[0m         proc\u001b[39m.\u001b[39mpid \u001b[39mfor\u001b[39;00m proc \u001b[39min\u001b[39;00m fitpool\u001b[39m.\u001b[39m_pool\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/afouto/PROJECTS/MIGRAINE/4_Conferences/2020_ESMRMB/11-Simulations/v011-simulate_xx_snr_independent_corrected.ipynb#X13sZmlsZQ%3D%3D?line=63'>64</a>\u001b[0m     ]  \u001b[39m# Get process IDs again\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/afouto/PROJECTS/MIGRAINE/4_Conferences/2020_ESMRMB/11-Simulations/v011-simulate_xx_snr_independent_corrected.ipynb#X13sZmlsZQ%3D%3D?line=64'>65</a>\u001b[0m     \u001b[39mif\u001b[39;00m (\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/afouto/PROJECTS/MIGRAINE/4_Conferences/2020_ESMRMB/11-Simulations/v011-simulate_xx_snr_independent_corrected.ipynb#X13sZmlsZQ%3D%3D?line=65'>66</a>\u001b[0m         fitpool_pids_new \u001b[39m!=\u001b[39m fitpool_pids_initial\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/afouto/PROJECTS/MIGRAINE/4_Conferences/2020_ESMRMB/11-Simulations/v011-simulate_xx_snr_independent_corrected.ipynb#X13sZmlsZQ%3D%3D?line=66'>67</a>\u001b[0m     ):  \u001b[39m# Check whether the IDs have changed from the initial values\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/afouto/PROJECTS/MIGRAINE/4_Conferences/2020_ESMRMB/11-Simulations/v011-simulate_xx_snr_independent_corrected.ipynb#X13sZmlsZQ%3D%3D?line=67'>68</a>\u001b[0m         \u001b[39mprint\u001b[39m(\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/afouto/PROJECTS/MIGRAINE/4_Conferences/2020_ESMRMB/11-Simulations/v011-simulate_xx_snr_independent_corrected.ipynb#X13sZmlsZQ%3D%3D?line=68'>69</a>\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/afouto/PROJECTS/MIGRAINE/4_Conferences/2020_ESMRMB/11-Simulations/v011-simulate_xx_snr_independent_corrected.ipynb#X13sZmlsZQ%3D%3D?line=69'>70</a>\u001b[0m         )  \u001b[39m# Yes, they changed: at least one worker has died! Exit with error\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "for m_i, method in enumerate(methods):\n",
    "    print(\"Processing \" + method + \"---------------------------------\")\n",
    "\n",
    "    if method == \"sc\":\n",
    "        path_out=path_sc\n",
    "\n",
    "    elif method == \"trunc\":\n",
    "        path_out=path_trunc\n",
    "    else:\n",
    "        path_out=path_random\n",
    "\n",
    "    for snr_i, snr in enumerate(SNR):\n",
    "        print(\"Processing snr:\" + str(snr) + \"---------------------------------\")\n",
    "        \n",
    "        for s_i, subset in enumerate(match):\n",
    "            print(\"Processing \" + subset + \"---------------------------------\")\n",
    "\n",
    "            bv1 = subset + \"_\" + method + \"_b0b1000b2000.bvec\"\n",
    "            bv2 = subset + \"_\" + method + \"_b0b1000b2000.bval\"\n",
    "\n",
    "            fbvecs = os.path.join(path_out, bv1)\n",
    "            fbvals = os.path.join(path_out, bv2)\n",
    "\n",
    "            bvals, bvecs = read_bvals_bvecs(str(fbvals), str(fbvecs))\n",
    "            gtab_sims = gradient_table(bvals, bvecs, b0_threshold=0)\n",
    "           \n",
    "            DWIs = np.zeros((nDTdirs * nReps, bvals.size))\n",
    "\n",
    "            for d_i in tqdm(np.arange(nDTdirs)):\n",
    "\n",
    "                time.sleep(0.3)\n",
    "                # for current simulated tensor direction\n",
    "                angles = DTdirs[d_i]\n",
    "                sticks = _check_directions(angles)\n",
    "\n",
    "                R = all_tensor_evecs(sticks)\n",
    "                DT = np.dot(np.dot(R, DT0), R.T)\n",
    "        \n",
    "                eigvals, eigvects = decompose_tensor(DT)\n",
    "\n",
    "                dt_rot = np.array([DT[0][0], DT[0][1], DT[1][1], DT[0][2], DT[1][2], DT[2][2]])\n",
    "\n",
    "                kt_rot = Wrotate(kt0, R.T)\n",
    "\n",
    "                input_list = []\n",
    "                for n_i in np.arange(d_i * nReps, (d_i + 1) * nReps, dtype=int):\n",
    "                    # Fitting DKI model to estimate the tensor parameters:\n",
    "                    slice_info = [n_i, gtab_sims, dt_rot, kt_rot, S0_sims, snr]\n",
    "                    input_list.append(slice_info)\n",
    "\n",
    "                if n_cores is None:\n",
    "                    n_cores = multiprocessing.cpu_count()\n",
    "\n",
    "                fitpool = multiprocessing.Pool(\n",
    "                    processes=n_cores)  # Create parallel processes\n",
    "                fitpool_pids_initial = [proc.pid for proc in fitpool._pool]  # Get initial process identifications (PIDs)\n",
    "                fitresults = fitpool.map_async(dki_fitting, input_list)  # Give jobs to the parallel processes\n",
    "\n",
    "                # Busy-waiting: until work is done, check whether any worker dies (in that case, PIDs would change!)\n",
    "                while not fitresults.ready():\n",
    "                    fitpool_pids_new = [\n",
    "                        proc.pid for proc in fitpool._pool\n",
    "                    ]  # Get process IDs again\n",
    "                    if (\n",
    "                        fitpool_pids_new != fitpool_pids_initial\n",
    "                    ):  # Check whether the IDs have changed from the initial values\n",
    "                        print(\n",
    "                            \"\"\n",
    "                        )  # Yes, they changed: at least one worker has died! Exit with error\n",
    "                        print(\n",
    "                            \"ERROR: some processes died during parallel fitting. Exiting with 1.\"\n",
    "                        )\n",
    "                        print(\"\")\n",
    "                        sys.exit(1)\n",
    "\n",
    "                # Work done: get results\n",
    "                fitlist = fitresults.get()\n",
    "\n",
    "                \n",
    "                # Collect fitting output and re-assemble MRI slices\n",
    "                for fit_i, fit_rep in enumerate(fitlist):\n",
    "                    DWIs[fit_rep[0], :] = fit_rep[1]\n",
    "                        \n",
    "            converted_array = np.asfarray(DWIs, dtype=np.float32)\n",
    "\n",
    "            nifti_array = converted_array.reshape((10, 10, 100, bvals.size))\n",
    "            nifti_file = nib.Nifti2Image(nifti_array, affine=np.eye(4))\n",
    "            \n",
    "            out_dir = os.path.join(path_to_save, 'snr{}'.format(snr), subset)\n",
    "            if not os.path.exists(out_dir):\n",
    "                os.makedirs(out_dir)\n",
    "                \n",
    "            nib.save(nifti_file, os.path.join(out_dir, 'dwi_sims_snr{}_{}_method-{}.nii'.format(snr, subset, method)))\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('project-dwi_subsampling': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "50a95c54e9956108271d2931e040fd7ce64b2f56e50f13cdae9ee435e56442f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
